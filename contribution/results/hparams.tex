\section{Réglage des hyper-paramètres}%
\label{sec.results.hparams}

Les résultats présentés dans Section~\ref{sub.results.training.results} sont satisfaisants.
Il n'est donc pas strictement nécessaire d'effectuer un réglage des hyperparamètres.
Cependant, il est possible en le faisant d'obtenir des résultats comparables 
en moins d'époques ou avec un modèle plus petit.
Pour cette raison, nous avons décidé de l'entamer.

\subsection{Configuration}%
\label{sub.results.hparams.config}

Nous avons fait le choix de restreindre la portée de ce réglage à deux hyperparamètres :
le taux d'apprentissage (\(\eta\) ou \verb|lr|) et le (\verb|dropout|).
Nous avons opté pour une recherche bayésienne avec des lois \(\log\)--uniformes sur les intervalles
\(\left[10^{-5}, 10^{-1}\right]\) et \([0.1, 0.5]\) respectivement.
Les autres hyperparamètres ont été fixés à leurs valeurs données dans Section~\ref{sub.results.training.hyperparameters}.

Pour chaque combinaison de \verb|lr| et \verb|dropout|, nous avons entraîné le modèle pendant 2 époques.
L'objectif de la recherche est de maximiser le score \gls{bleu} sur le corpus de validation.
Nous avons limité le nombre d'essais à 20.

\subsection{Résultats}%
\label{sub.results.hparams.results}

Les 20 essais ont été effectués en 2~h~17~min~13~s~11~ms.
Les résultats sont présentés dans Figure~\ref{fig.results.hparams}.
\begin{figure}[hbt]
    \centering
    \includegraphics[width=.8\textwidth]{assets/images/sweep.png}
    \caption{Résultats de la recherche bayésienne des hyperparamètres.}%
    \label{fig.results.hparams}
\end{figure}
La figure en question est une visualisation en coordonnées parallèles des résultats.
L'axe de gauche représente la valeur de \verb|dropout| sur une échelle linéaire, 
celui du milieu la valeur de \verb|lr| sur une échelle logarithmique 
et celui de droite le score \gls{bleu} sur une échelle de 0 à 100.
Un essai est représenté par une courbe qui relie les 3 points correspondants sur les 3 axes.
La couleur de la courbe indique le score \gls{bleu} associé.
Elle est interpolée entre le violet (0\%) et l'orange (100\%).
Les mêmes informations sont présentes dans Table~\ref{tab.results.hparams} sous forme numérique.

\begin{table}[htb]
    \begin{center}
        \begin{tabular}{llc}
            \toprule
            \verb|dropout| & \verb|lr| & \verb|bleu_score|(\%) \\
            \midrule
            0.263684       & 0.000049 &        0.000000        \\
            0.155497       & 0.018280 &        0.000000        \\
            0.324059       & 0.007670 &        5.386821        \\
            0.186584       & 0.000328 &       37.148937        \\
            0.101305       & 0.001844 &       68.802765        \\
            0.101600       & 0.001849 &       70.371147        \\
            0.113328       & 0.001201 &       67.655579        \\
            0.111991       & 0.086200 &        0.000000        \\
            0.496975       & 0.000011 &        0.000000        \\
            0.118870       & 0.001259 &       69.372551        \\
            0.106921       & 0.001636 &       68.679092        \\
            0.124348       & 0.001989 &       67.192963        \\
            0.105984       & 0.000305 &       42.627316        \\
            0.101419       & 0.006308 &       54.094482        \\
            0.101742       & 0.001170 &       68.488480        \\
            0.135847       & 0.001025 &       65.854347        \\
            0.270016       & 0.013106 &        2.553007        \\
            0.147102       & 0.000772 &       60.324165        \\
            0.203584       & 0.000013 &        0.000000        \\
            0.425286       & 0.013681 &        1.264920        \\
            \bottomrule
        \end{tabular}
    
    \end{center}
    \caption{Résultats de la recherche bayésienne des hyperparamètres.}%
    \label{tab.results.hparams}
\end{table}

On observe sur la figure un regroupement des lignes oranges (les meilleurs essais) 
dans la région qui correspond à \verb|dropout| \(\in[0.1, 0.15]\) et \(\eta\approx 10 ^{-3}\).
Cela est aussi apparent sur le tableau.
\begin{table}[hbt]
    \begin{center}
        \begin{tabular}{|l|c|c|}
            \cline{2-3}
            \multicolumn{1}{c|}{} & Importance & Corrélation \\
            \hline
            \verb|dropout|        & 63.9\%     & \(- 0.899\)     \\
            \hline
            \verb|lr|             & 36.1\%     & \(- 0.647\)     \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Importance et corrélation des hyperparamètres.}
    \label{tab.results.hparam.corr}
\end{table}
\begin{figure}[hbt]
    \begin{center}
        \includegraphics[width=.7\textwidth]{assets/python/importance.pdf}
    \end{center}
    \caption{Importance des hyperparamètres et corrélation avec le score \glsfmtshort{bleu}.}%
    \label{fig.results.hparam.corr}
\end{figure}
Une analyse factorielle sur les essais effectués nous permet d'estimer l'importance des hyperparamètres 
ainsi que leurs corrélations avec le score \gls{bleu}.
Ils sont tous deux négativement corrélés avec ce dernier (\gls{bleu} augmente quand l'un diminue).
Le \verb|dropout| est le plus important entre les deux 
(voir Table~\ref{tab.results.hparam.corr} et Figure~\ref{fig.results.hparam.corr}).
La meilleure valeur du score \gls{bleu} est obtenue 
avec \verb|dropout| \(\approx 0.101599\) et \(\eta\approx 0.0018488801\).
Pour cette valeur, le score \gls{bleu} sur le corpus de validation est de 70.37\% après 2 époques.