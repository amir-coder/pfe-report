\section{\Glsfmtlong{nmt}}

La deuxième partie de notre système (et celle qui réalise sa fonction principale) est le modèle de traduction.
Ce modèle corrige la parole aphasique pour la rendre plus compréhensible.
Dans cette section, nous allons détailler les étapes de sa construction.

\subsection{Création d'un corpus parallèle}

L'entraînement d'un modèle de traduction nécessite la présence d'un \emph{corpus parallèle}
i.e. un corpus contenant les mêmes phrases dans plusieurs langues (dans notre cas, Français et Français aphasique).
Cependant, un tel corpus n'existe pas. 
Il est donc nécessaire de le créer.
La création d'un tel corpus nécessite la collecte d'un corpus de parole aphasique de taille suffisante.
Ce corpus doit être en suite traiter par des experts pour corriger les erreurs dedans.
Or, nous avons déjà établie qu'un corpus de parole aphasique de taille suffisante n'existe pas.
Ce chemin donc est infranchissable dans ce moment.

L'alternative proposée dans \cite{Smaili_Langlois_Pribil_2022} --- et celle que nous prenons --- 
est de créer un corpus synthétique.
C-À-D, partir d'un corpus de parole normale et le modifier pour introduire 
des erreurs similaires à celles trouvées dans la parole aphasique.

\subsubsection{Corpus de parole normale}

Nous avons utilisé le corpus \texttt{fra\_mixed100k} de 
la \emph{\foreignlanguage{english}{Leipzig Corpora Collection}}~\cite{Goldhahn_Eckart_Quasthoff}.
Il s'agit d'un corpus de 100000 phrases Françaises collectées de plusieurs sites web.
Ces phrases sont diverses dans leur contenu, longueur, vocabulaire et structure grammaticale.

\subsubsection{Extraction du vocabulaire et selection des mots à modifier}

Les erreurs causée par l'aphasie de Broca ne sont pas déterministes.
Un individu qui en souffre ne se trompe pas sur tous les mots, ni de la même manière sur le même mot.
Cependant, les erreurs ne sont pas uniformément réparties sur le vocabulaire.
Naturellement, un tel individu à tendance à se tromper plus sur les mots ``\emph{difficiles}''.
Il est aussi plus susceptible de se tromper sur les mots qu'il utilise le plus souvent.
On peut donc s'attendre à un biais pour les mots fréquents et difficiles.

Pour simuler ce biais dans notre corpus, nous avons extrait le vocabulaire du corpus.
Puis, nous avons sélectionné les mots ``\emph{difficiles}''. 
Nous avons considéré un mot ``\emph{difficile}'' s'il est long (plus de 2 syllabes).
Nous avons considéré ses mots dans l'ordre de leur fréquence dans le corpus (les 1000 premiers).

\subsubsection{Génération et filtrage des erreurs synthétiques}

Les mots sélectionnés à l'étape précédente sont donnés à chatGPT 
qui est charger de générer 10 erreurs pour chaque mots dans le style d'un individu souffrant de l'aphasie de Broca.
Le résultats de cette operation est une liste de 10000 couples (mot, erreur).

Ces couples sont filtrés manuellement pour supprimer les erreurs trop similaires au mot original 
(par exemple celle qui en different uniquement par la suppression d'une lettre)
et les erreurs dissimilaire à celle produite par un individu aphasique.
Cela a donné une moyenne de 5 erreurs retenues par mot.

